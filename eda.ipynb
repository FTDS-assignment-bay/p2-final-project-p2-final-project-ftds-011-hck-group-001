{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aj = pd.read_excel('dataset.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'C536379'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Hactiv8\\Final Project\\p2-final-project-p2-final-project-ftds-011-hck-group-001\\eda.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hactiv8/Final%20Project/p2-final-project-p2-final-project-ftds-011-hck-group-001/eda.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m aj\u001b[39m.\u001b[39mreplace(to_replace\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[A-Z]\u001b[39m\u001b[39m'\u001b[39m,value\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Hactiv8/Final%20Project/p2-final-project-p2-final-project-ftds-011-hck-group-001/eda.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m aj[aj\u001b[39m.\u001b[39mcolumns[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m aj[aj\u001b[39m.\u001b[39;49mcolumns[\u001b[39m0\u001b[39;49m]]\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[39m=\u001b[39m [ser\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy) \u001b[39mfor\u001b[39;00m _, ser \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6535\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    415\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    416\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    417\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    418\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    419\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    618\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    239\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[39m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[39m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    185\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    132\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m dtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    136\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'C536379'"
     ]
    }
   ],
   "source": [
    "aj.replace(to_replace=r'^[A-Z]',value='',inplace=True)\n",
    "aj[aj.columns[0]] = aj[aj.columns[0]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoiceno</th>\n",
       "      <th>stockcode</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>invoicedate</th>\n",
       "      <th>unitprice</th>\n",
       "      <th>customerid</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [invoiceno, stockcode, description, quantity, invoicedate, unitprice, customerid, country]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('clean.csv')\n",
    "test.info()\n",
    "dropped = test.select_dtypes(include='int')\n",
    "st = ''\n",
    "for i in dropped.columns:\n",
    "    st+=f' {i} < 0 or'\n",
    "st = st[:-2]\n",
    "\n",
    "drop_index = dropped.query(st).index\n",
    "\n",
    "drop_df = test.drop(index=drop_index)\n",
    "\n",
    "drop_df.query(f'quantity < 0 or customerid < 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "  \n",
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load('data/clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|invoiceno|stockcode|         description|quantity|        invoicedate|unitprice|customerid|       country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|     17850|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|     17850|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|     17850|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|     17850|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|     17850|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|     13047|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|     13047|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|     13047|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|     13047|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|     13047|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|     13047|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|     13047|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|     13047|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|     13047|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|     13047|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|     13047|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['invoiceno',\n",
       " 'stockcode',\n",
       " 'description',\n",
       " 'quantity',\n",
       " 'invoicedate',\n",
       " 'unitprice',\n",
       " 'customerid',\n",
       " 'country']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ganti nama kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.toDF(*[i.upper() for i in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(invoiceno='536365', stockcode='85123A', description='WHITE HANGING HEART T-LIGHT HOLDER', quantity=6, invoicedate=datetime.datetime(2010, 12, 1, 8, 26), unitprice=2.55, customerid=17850, country='United Kingdom'),\n",
       " Row(invoiceno='536365', stockcode='71053', description='WHITE METAL LANTERN', quantity=6, invoicedate=datetime.datetime(2010, 12, 1, 8, 26), unitprice=3.39, customerid=17850, country='United Kingdom'),\n",
       " Row(invoiceno='536365', stockcode='84406B', description='CREAM CUPID HEARTS COAT HANGER', quantity=8, invoicedate=datetime.datetime(2010, 12, 1, 8, 26), unitprice=2.75, customerid=17850, country='United Kingdom'),\n",
       " Row(invoiceno='536365', stockcode='84029G', description='KNITTED UNION FLAG HOT WATER BOTTLE', quantity=6, invoicedate=datetime.datetime(2010, 12, 1, 8, 26), unitprice=3.39, customerid=17850, country='United Kingdom'),\n",
       " Row(invoiceno='536365', stockcode='84029E', description='RED WOOLLY HOTTIE WHITE HEART.', quantity=6, invoicedate=datetime.datetime(2010, 12, 1, 8, 26), unitprice=3.39, customerid=17850, country='United Kingdom'),\n",
       " Row(invoiceno='536365', stockcode='22752', description='SET 7 BABUSHKA NESTING BOXES', quantity=2, invoicedate=datetime.datetime(2010, 12, 1, 8, 26), unitprice=7.65, customerid=17850, country='United Kingdom'),\n",
       " Row(invoiceno='536365', stockcode='21730', description='GLASS STAR FROSTED T-LIGHT HOLDER', quantity=6, invoicedate=datetime.datetime(2010, 12, 1, 8, 26), unitprice=4.25, customerid=17850, country='United Kingdom'),\n",
       " Row(invoiceno='536366', stockcode='22633', description='HAND WARMER UNION JACK', quantity=6, invoicedate=datetime.datetime(2010, 12, 1, 8, 28), unitprice=1.85, customerid=17850, country='United Kingdom'),\n",
       " Row(invoiceno='536366', stockcode='22632', description='HAND WARMER RED POLKA DOT', quantity=6, invoicedate=datetime.datetime(2010, 12, 1, 8, 28), unitprice=1.85, customerid=17850, country='United Kingdom'),\n",
       " Row(invoiceno='536367', stockcode='84879', description='ASSORTED COLOUR BIRD ORNAMENT', quantity=32, invoicedate=datetime.datetime(2010, 12, 1, 8, 34), unitprice=1.69, customerid=13047, country='United Kingdom')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melihat Tipe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(tsar):\n",
    "    for i in range(len(tsar.columns)):\n",
    "        print(f\"{tsar.columns[i]} =\",tsar.schema[tsar.columns[i]].dataType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengubah Tipe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoiceno = StringType()\n",
      "stockcode = StringType()\n",
      "description = StringType()\n",
      "quantity = IntegerType()\n",
      "invoicedate = TimestampType()\n",
      "unitprice = DoubleType()\n",
      "customerid = IntegerType()\n",
      "country = StringType()\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "# for i in range(len(df.columns)):\n",
    "#     df = df.withColumn(df.columns[i],df[df.columns[i]].cast(StringType()))\n",
    "\n",
    "info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoiceno = StringType()\n",
      "stockcode = StringType()\n",
      "description = StringType()\n",
      "quantity = IntegerType()\n",
      "invoicedate = TimestampType()\n",
      "unitprice = DoubleType()\n",
      "customerid = IntegerType()\n",
      "country = StringType()\n"
     ]
    }
   ],
   "source": [
    "info(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membaca File Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\pandas\\__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoiceno</th>\n",
       "      <th>stockcode</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>invoicedate</th>\n",
       "      <th>unitprice</th>\n",
       "      <th>customerid</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536636</th>\n",
       "      <td>581587</td>\n",
       "      <td>22613</td>\n",
       "      <td>PACK OF 20 SPACEBOY NAPKINS</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536637</th>\n",
       "      <td>581587</td>\n",
       "      <td>22899</td>\n",
       "      <td>CHILDREN'S APRON DOLLY GIRL</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536638</th>\n",
       "      <td>581587</td>\n",
       "      <td>23254</td>\n",
       "      <td>CHILDRENS CUTLERY DOLLY GIRL</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536639</th>\n",
       "      <td>581587</td>\n",
       "      <td>23255</td>\n",
       "      <td>CHILDRENS CUTLERY CIRCUS PARADE</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536640</th>\n",
       "      <td>581587</td>\n",
       "      <td>22138</td>\n",
       "      <td>BAKING SET 9 PIECE RETROSPOT</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536641 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       invoiceno stockcode                          description quantity  \\\n",
       "0         536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER        6   \n",
       "1         536365     71053                  WHITE METAL LANTERN        6   \n",
       "2         536365    84406B       CREAM CUPID HEARTS COAT HANGER        8   \n",
       "3         536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE        6   \n",
       "4         536365    84029E       RED WOOLLY HOTTIE WHITE HEART.        6   \n",
       "...          ...       ...                                  ...      ...   \n",
       "536636    581587     22613          PACK OF 20 SPACEBOY NAPKINS       12   \n",
       "536637    581587     22899         CHILDREN'S APRON DOLLY GIRL         6   \n",
       "536638    581587     23254        CHILDRENS CUTLERY DOLLY GIRL         4   \n",
       "536639    581587     23255      CHILDRENS CUTLERY CIRCUS PARADE        4   \n",
       "536640    581587     22138        BAKING SET 9 PIECE RETROSPOT         3   \n",
       "\n",
       "                invoicedate unitprice customerid         country  \n",
       "0       2010-12-01 08:26:00      2.55      17850  United Kingdom  \n",
       "1       2010-12-01 08:26:00      3.39      17850  United Kingdom  \n",
       "2       2010-12-01 08:26:00      2.75      17850  United Kingdom  \n",
       "3       2010-12-01 08:26:00      3.39      17850  United Kingdom  \n",
       "4       2010-12-01 08:26:00      3.39      17850  United Kingdom  \n",
       "...                     ...       ...        ...             ...  \n",
       "536636  2011-12-09 12:50:00      0.85      12680          France  \n",
       "536637  2011-12-09 12:50:00       2.1      12680          France  \n",
       "536638  2011-12-09 12:50:00      4.15      12680          France  \n",
       "536639  2011-12-09 12:50:00      4.15      12680          France  \n",
       "536640  2011-12-09 12:50:00      4.95      12680          France  \n",
       "\n",
       "[536641 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.columns = [i.lower() for i in dataframe.columns]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_20820\\825632357.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "ename": "DistributionNotFound",
     "evalue": "The 'crealytics' distribution was not found and is required by the application",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDistributionNotFound\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32md:\\Hactiv8\\Final Project\\p2-final-project-p2-final-project-ftds-011-hck-group-001\\eda.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hactiv8/Final%20Project/p2-final-project-p2-final-project-ftds-011-hck-group-001/eda.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpkg_resources\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Hactiv8/Final%20Project/p2-final-project-p2-final-project-ftds-011-hck-group-001/eda.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pkg_resources\u001b[39m.\u001b[39;49mget_distribution(\u001b[39m'\u001b[39;49m\u001b[39mcrealytics\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py:528\u001b[0m, in \u001b[0;36mget_distribution\u001b[1;34m(dist)\u001b[0m\n\u001b[0;32m    526\u001b[0m     dist \u001b[39m=\u001b[39m Requirement\u001b[39m.\u001b[39mparse(dist)\n\u001b[0;32m    527\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dist, Requirement):\n\u001b[1;32m--> 528\u001b[0m     dist \u001b[39m=\u001b[39m get_provider(dist)\n\u001b[0;32m    529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dist, Distribution):\n\u001b[0;32m    530\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string, Requirement, or Distribution\u001b[39m\u001b[39m\"\u001b[39m, dist)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py:400\u001b[0m, in \u001b[0;36mget_provider\u001b[1;34m(moduleOrReq)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(moduleOrReq, Requirement):\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mreturn\u001b[39;00m working_set\u001b[39m.\u001b[39mfind(moduleOrReq) \u001b[39mor\u001b[39;00m require(\u001b[39mstr\u001b[39;49m(moduleOrReq))[\u001b[39m0\u001b[39m]\n\u001b[0;32m    401\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     module \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[moduleOrReq]\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py:968\u001b[0m, in \u001b[0;36mWorkingSet.require\u001b[1;34m(self, *requirements)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequire\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mrequirements):\n\u001b[0;32m    960\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Ensure that distributions matching `requirements` are activated\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \n\u001b[0;32m    962\u001b[0m \u001b[39m    `requirements` must be a string or a (possibly-nested) sequence\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[39m    included, even if they were already activated in this working set.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 968\u001b[0m     needed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresolve(parse_requirements(requirements))\n\u001b[0;32m    970\u001b[0m     \u001b[39mfor\u001b[39;00m dist \u001b[39min\u001b[39;00m needed:\n\u001b[0;32m    971\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(dist)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py:829\u001b[0m, in \u001b[0;36mWorkingSet.resolve\u001b[1;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m req_extras\u001b[39m.\u001b[39mmarkers_pass(req, extras):\n\u001b[0;32m    827\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 829\u001b[0m dist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_dist(\n\u001b[0;32m    830\u001b[0m     req, best, replace_conflicting, env, installer, required_by, to_activate\n\u001b[0;32m    831\u001b[0m )\n\u001b[0;32m    833\u001b[0m \u001b[39m# push the new requirements onto the stack\u001b[39;00m\n\u001b[0;32m    834\u001b[0m new_requirements \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mrequires(req\u001b[39m.\u001b[39mextras)[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py:870\u001b[0m, in \u001b[0;36mWorkingSet._resolve_dist\u001b[1;34m(self, req, best, replace_conflicting, env, installer, required_by, to_activate)\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[39mif\u001b[39;00m dist \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m             requirers \u001b[39m=\u001b[39m required_by\u001b[39m.\u001b[39mget(req, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 870\u001b[0m             \u001b[39mraise\u001b[39;00m DistributionNotFound(req, requirers)\n\u001b[0;32m    871\u001b[0m     to_activate\u001b[39m.\u001b[39mappend(dist)\n\u001b[0;32m    872\u001b[0m \u001b[39mif\u001b[39;00m dist \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m req:\n\u001b[0;32m    873\u001b[0m     \u001b[39m# Oops, the \"best\" so far conflicts with a dependency\u001b[39;00m\n",
      "\u001b[1;31mDistributionNotFound\u001b[0m: The 'crealytics' distribution was not found and is required by the application"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "pkg_resources.get_distribution('crealytics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o147.load.\n: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: com.crealytics.spark.excel. Please find packages at `https://spark.apache.org/third-party-projects.html`.\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.lang.ClassNotFoundException: com.crealytics.spark.excel.DefaultSource\r\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:593)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\r\n\tat scala.util.Failure.orElse(Try.scala:224)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\r\n\t... 15 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\Hactiv8\\Final Project\\p2-final-project-p2-final-project-ftds-011-hck-group-001\\eda.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hactiv8/Final%20Project/p2-final-project-p2-final-project-ftds-011-hck-group-001/eda.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m spark1 \u001b[39m=\u001b[39m SparkSession\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mappName(\u001b[39m\"\u001b[39m\u001b[39mPANDAS\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mconfig(\u001b[39m\"\u001b[39m\u001b[39mspark.jars.packages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcom.crealytics:spark-excel_2.12:0.13.7\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mgetOrCreate()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Hactiv8/Final%20Project/p2-final-project-p2-final-project-ftds-011-hck-group-001/eda.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pdf \u001b[39m=\u001b[39m spark1\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39;49mformat(\u001b[39m\"\u001b[39;49m\u001b[39mcom.crealytics.spark.excel\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49moptions(header\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTrue\u001b[39;49m\u001b[39m'\u001b[39;49m,inferSchema\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTrue\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mdataset.xlsx\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\readwriter.py:307\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    306\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mload(path))\n\u001b[0;32m    308\u001b[0m \u001b[39melif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(path) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o147.load.\n: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: com.crealytics.spark.excel. Please find packages at `https://spark.apache.org/third-party-projects.html`.\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.lang.ClassNotFoundException: com.crealytics.spark.excel.DefaultSource\r\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:593)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\r\n\tat scala.util.Failure.orElse(Try.scala:224)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\r\n\t... 15 more\r\n"
     ]
    }
   ],
   "source": [
    "spark1 = SparkSession.builder.appName(\"PANDAS\").config(\"spark.jars.packages\", \"com.crealytics:spark-excel_2.12:0.13.7\").getOrCreate()\n",
    "\n",
    "pdf = spark1.read.format(\"com.crealytics.spark.excel\").options(header='True',inferSchema='True').load('dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
